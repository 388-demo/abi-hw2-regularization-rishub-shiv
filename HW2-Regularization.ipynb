{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import sklearn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = pd.read_csv(\"housing.csv\")\n",
    "\n",
    "housing = housing.iloc[:5000,:] # only use the first 5000 observations\n",
    "\n",
    "### Attribute Combinations\n",
    "housing[\"rooms_per_household\"] = housing[\"total_rooms\"]/housing[\"households\"]\n",
    "housing[\"bedrooms_per_room\"] = housing[\"total_bedrooms\"]/housing[\"total_rooms\"]\n",
    "housing[\"population_per_household\"]=housing[\"population\"]/housing[\"households\"]\n",
    "\n",
    "# housing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "num_pipeline = make_pipeline(SimpleImputer(strategy=\"median\"), StandardScaler())\n",
    "\n",
    "cat_pipeline = make_pipeline(\n",
    "    SimpleImputer(strategy=\"most_frequent\"),\n",
    "    OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "\n",
    "\n",
    "from sklearn.compose import make_column_selector, make_column_transformer\n",
    "\n",
    "preprocessing = make_column_transformer(\n",
    "    (num_pipeline, make_column_selector(dtype_include=np.number)),\n",
    "    (cat_pipeline, make_column_selector(dtype_include=object)),\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training X and y variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_set.drop(\"median_house_value\", axis=1)\n",
    "train_y = train_set[\"median_house_value\"].copy()\n",
    "\n",
    "train_X_prepared = preprocessing.fit_transform(train_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing X and y variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = test_set.drop(\"median_house_value\", axis=1)\n",
    "test_y = test_set[\"median_house_value\"].copy()\n",
    "\n",
    "# transform X in testing set\n",
    "test_X_prepared = preprocessing.transform(test_X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1:** \n",
    "\n",
    "1. Fit a Linear Regression model using `train_X_prepared` as predictor, and `train_y` as response.\n",
    "2. Then, calculate the testing RMSE using `test_X_prepared` as predictor, and `test_y` as response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model  = LinearRegression()\n",
    "model.fit(train_X_prepared,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72129.57449006115"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "# from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "train_pred = model.predict(test_X_prepared)\n",
    "\n",
    "train_mse = mean_squared_error(test_y, train_pred, squared=False)\n",
    "\n",
    "\n",
    "train_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2:**\n",
    "1. Fit a Ridge Regression model with tuning parameter $\\alpha=10$ using `train_X_prepared` as predictor, and `train_y` as response. Then, calculate the testing RMSE using `test_X_prepared` as predictor, and `test_y` as response.\n",
    "\n",
    "2. Use grid search to choose the best $\\alpha$ value (You may need multiple grid searches). Then use the Ridge model with the best alpha value to calculate the testing RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72195.3401723892"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge_reg = Ridge(alpha=10, solver=\"cholesky\")\n",
    "\n",
    "ridge_reg.fit(train_X_prepared,train_y)\n",
    "\n",
    "test_pred = ridge_reg.predict(test_X_prepared)\n",
    "train_mse = mean_squared_error(test_y, test_pred,squared=False)\n",
    "train_mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 : 125\n",
      "Ridge(alpha=125)\n",
      "72861.5404759224\n",
      "4 : 168\n",
      "Ridge(alpha=168)\n",
      "73073.72379473266\n",
      "5 : 156\n",
      "Ridge(alpha=156)\n",
      "73014.99242886041\n",
      "6 : 168\n",
      "Ridge(alpha=168)\n",
      "73073.72379473266\n",
      "7 : 63\n",
      "Ridge(alpha=63)\n",
      "72532.67654606629\n",
      "8 : 176\n",
      "Ridge(alpha=176)\n",
      "73112.78529897328\n",
      "9 : 61\n",
      "Ridge(alpha=61)\n",
      "72521.13672345363\n",
      "10 : 183\n",
      "Ridge(alpha=183)\n",
      "73146.93363745426\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "ridge_estimator = Ridge()\n",
    "\n",
    "params = {'alpha': [x for x in range(1,201)]}\n",
    "\n",
    "for i in range(3,11):\n",
    "\n",
    "    gridcv_ridge_model = GridSearchCV(Ridge(), params, cv=i,scoring='neg_root_mean_squared_error')\n",
    "\n",
    "    gridcv_ridge_model.fit(train_X_prepared, train_y)\n",
    "\n",
    "\n",
    "    print(f\"{i} :\", gridcv_ridge_model.best_params_['alpha'])\n",
    "    print(gridcv_ridge_model.best_estimator_)\n",
    "\n",
    "    test_pred = gridcv_ridge_model.predict(test_X_prepared)\n",
    "    train_mse = mean_squared_error(test_y, test_pred,squared=False)\n",
    "    print(train_mse)\n",
    "  \n",
    "\n",
    "    # 75-95\n",
    "\n",
    "    #122,123,166,157,165,63,176,61,186"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 72130.19582574743\n",
      "10 72195.3401723892\n",
      "122 72846.4739551109\n",
      "123 72851.50180248583\n",
      "166 73063.94913957632\n",
      "157 73019.89560523246\n",
      "165 73059.06005418775\n",
      "63 72532.67654606629\n",
      "176 73112.78529897328\n",
      "61 72521.13672345363\n",
      "186 73161.5649612211\n",
      "75 72600.29515074384\n",
      "76 72605.81508546752\n",
      "77 72611.31879394961\n",
      "78 72616.80657834343\n",
      "79 72622.27873764264\n",
      "80 72627.73556759395\n",
      "81 72633.17736062066\n",
      "82 72638.60440575697\n",
      "83 72644.01698859165\n",
      "84 72649.41539122051\n",
      "85 72654.79989220692\n",
      "86 72660.17076655004\n",
      "87 72665.52828565943\n",
      "88 72670.87271733645\n",
      "89 72676.20432576108\n",
      "90 72681.52337148422\n",
      "91 72686.83011142476\n",
      "92 72692.12479887118\n",
      "93 72697.40768348728\n",
      "94 72702.67901132129\n",
      "95 72707.93902481889\n",
      "96 72713.18796283899\n",
      "97 72718.42606067234\n",
      "98 72723.65355006288\n",
      "99 72728.87065923127\n",
      "100 72734.07761290052\n",
      "101 72739.27463232366\n",
      "102 72744.46193531287\n",
      "103 72749.6397362704\n",
      "104 72754.80824622072\n",
      "72130.19582574743\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LASSO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3:**\n",
    "1. Fit a LASSO Regression model with tuning parameter $\\alpha=1000$ using `train_X_prepared` as predictor, and `train_y` as response. Then, calculate the testing RMSE. Can the LASSO model help select variables?\n",
    "2. Use grid search to choose the best $\\alpha$ value (You may need multiple grid searches). Use the LASSO model with the best $alpha$ value to calculate the testing RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73037.08337454066"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso_reg = Lasso(alpha=1000)\n",
    "lasso_reg.fit(train_X_prepared, train_y)\n",
    "\n",
    "\n",
    "test_pred = lasso_reg.predict(test_X_prepared)\n",
    "train_mse = mean_squared_error(test_y, test_pred,squared=False)\n",
    "train_mse\n",
    "\n",
    "# Yes, the lasso model can help select variables because it selects variables with non-zero coefficients and removes those with zero coefficients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 : 242\n",
      "Lasso(alpha=242)\n",
      "72328.36827505077\n",
      "4 : 350\n",
      "Lasso(alpha=350)\n",
      "72393.58738970847\n",
      "5 : 257\n",
      "Lasso(alpha=257)\n",
      "72336.72147259413\n",
      "6 : 297\n",
      "Lasso(alpha=297)\n",
      "72360.15623711773\n",
      "7 : 766\n",
      "Lasso(alpha=766)\n",
      "72749.20088555175\n",
      "8 : 300\n",
      "Lasso(alpha=300)\n",
      "72361.96997717892\n",
      "9 : 758\n",
      "Lasso(alpha=758)\n",
      "72740.59501510796\n",
      "10 : 300\n",
      "Lasso(alpha=300)\n",
      "72361.96997717892\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "params = {'alpha': [x for x in range(200,1000)]}\n",
    "\n",
    "for i in range(3,11):\n",
    "\n",
    "    gridcv_ridge_model = GridSearchCV(Lasso(), params, cv=i,scoring='neg_root_mean_squared_error')\n",
    "\n",
    "    gridcv_ridge_model.fit(train_X_prepared, train_y)\n",
    "\n",
    "\n",
    "    print(f\"{i} :\", gridcv_ridge_model.best_params_['alpha'])\n",
    "    print(gridcv_ridge_model.best_estimator_)\n",
    "\n",
    "    test_pred = gridcv_ridge_model.predict(test_X_prepared)\n",
    "    train_mse = mean_squared_error(test_y, test_pred,squared=False)\n",
    "    print(train_mse)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elastic Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4:**\n",
    "1. Fit an Elastic Regression model with `alpha=10` and `l1_ratio=0.1` using `train_X_prepared` as predictor, and `train_y` as response. Then, calculate the testing RMSE. Can the LASSO model help select variables?\n",
    "2. Use grid search to choose the best settings for $alpha$ and `l1_ratio` value (You may need multiple grid searches). Use the elastic net model with the best settings to calculate the testing RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet, ElasticNetCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Fit Elastic Regression model with alpha=10 and l1_ratio=0.1\n",
    "elastic_net = ElasticNet(alpha=10, l1_ratio=0.1)\n",
    "elastic_net.fit(train_X_prepared, train_y)\n",
    "\n",
    "# Calculate testing RMSE\n",
    "test_predictions = elastic_net.predict(test_X_prepared)\n",
    "test_rmse = mean_squared_error(test_y, test_predictions, squared=False)\n",
    "print(\"Testing RMSE for Elastic Regression (alpha=10, l1_ratio=0.1):\", test_rmse)\n",
    "\n",
    "# Check coefficients to see if LASSO helps in variable selection\n",
    "print(\"Coefficients:\", elastic_net.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'alpha': [0.1, 1, 10, 100], 'l1_ratio': [0.1, 0.5, 0.9]}\n",
    "grid_search = GridSearchCV(ElasticNet(), param_grid, scoring='neg_root_mean_squared_error', cv=5)\n",
    "grid_search.fit(train_X_prepared, train_y)\n",
    "\n",
    "# Get best settings\n",
    "best_alpha = grid_search.best_params_['alpha']\n",
    "best_l1_ratio = grid_search.best_params_['l1_ratio']\n",
    "print(\"Best alpha:\", best_alpha)\n",
    "print(\"Best l1_ratio:\", best_l1_ratio)\n",
    "\n",
    "# Use Elastic Net model with best settings\n",
    "best_elastic_net = ElasticNet(alpha=best_alpha, l1_ratio=best_l1_ratio)\n",
    "best_elastic_net.fit(train_X_prepared, train_y)\n",
    "\n",
    "# Calculate testing RMSE with best Elastic Net model\n",
    "best_test_predictions = best_elastic_net.predict(test_X_prepared)\n",
    "best_test_rmse = mean_squared_error(test_y, best_test_predictions, squared=False)\n",
    "print(\"Testing RMSE for best Elastic Net model:\", best_test_rmse)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
